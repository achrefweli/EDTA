{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99a8e72",
   "metadata": {},
   "source": [
    " Clone Reference Repository\n",
    "This command clones the StockEmotions GitHub repository, which contains financial sentiment data and models used as a reference for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10cbe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/adlnlp/StockEmotions.git ##remove this line\n",
    "\n",
    "## COMMENT: It's better that your project dont have an internal dependency with an external repository (that it's not your own)\n",
    "## COMMENT: Moreover, if that repo changes, you will have to update your project\n",
    "##¬†COMMENT: I've included those files in your project. The dataset/StockEmotions, it's a simple folder without the .git folder/that external repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e9e0a",
   "metadata": {},
   "source": [
    "This cell loads the tweet-level sentiment data from the StockEmotions repository (train, val, and test splits).\n",
    "It filters relevant columns, renames them for consistency, merges all splits, parses the dates, and maps sentiment labels (0 ‚Üí bearish, 1 ‚Üí bullish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2bfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment distribution: sentiment\n",
      "bullish    5474\n",
      "bearish    4526\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>$AMZN Dow futures up by 100 points already ü•≥</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>$TSLA Daddy's drinkin' eArly tonight! Here's t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>$AAPL We‚Äôll been riding since last December fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>$TSLA happy new year, 2020, everyoneüç∑üéâüôè</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>$TSLA haha just a collection of greats...\"Mars...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker                                               text  \\\n",
       "0  2020-01-01   AMZN       $AMZN Dow futures up by 100 points already ü•≥   \n",
       "1  2020-01-01   TSLA  $TSLA Daddy's drinkin' eArly tonight! Here's t...   \n",
       "2  2020-01-01   AAPL  $AAPL We‚Äôll been riding since last December fr...   \n",
       "3  2020-01-01   TSLA            $TSLA happy new year, 2020, everyoneüç∑üéâüôè   \n",
       "4  2020-01-01   TSLA  $TSLA haha just a collection of greats...\"Mars...   \n",
       "\n",
       "   sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "base = Path(\"dataset/StockEmotions/tweet\")\n",
    "df_list = []\n",
    "for split in [\"train_stockemo\",\"val_stockemo\",\"test_stockemo\"]: ## We are joining three datasets (training, validation and test)\n",
    "    path = base / f\"{split}.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['date','ticker','original','senti_label']]\n",
    "    df.rename(columns={'original':'text', 'senti_label':'sentiment'}, inplace=True)\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "print(\"Sentiment distribution:\", df['sentiment'].value_counts())\n",
    "# df['sentiment'] = df['sentiment'].map({0:'bearish',1:'bullish'}) ## Alert!!!!\n",
    "# map_labels = {'positive': 'bullish', 'negative': 'bearish'} ##¬†YOU USE THIS DICT IN NEXT CELLS: BETTER ### ALERT THE KEY_VALUE STRUCTURE\n",
    "map_labels = {'bullish': 'positive', 'bearish': 'negative'}\n",
    "df['sentiment'] = df['sentiment'].map(map_labels)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e20153",
   "metadata": {},
   "source": [
    "Shows dataset size, unique tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in the dataset: 10000\n",
      "Companies in the dataset: 37\n",
      "\t+ in the dataset: ['AMZN' 'TSLA' 'AAPL' 'HD' 'NVDA' 'GOOGL' 'NFLX' 'FB' 'DIS' 'BA' 'WMT'\n",
      " 'TSM' 'BABA' 'V' 'SBUX' 'BAC' 'UNH' 'XOM' 'MSFT' 'GOOG' 'PFE' 'CVX'\n",
      " 'PYPL' 'MCD' 'JPM' 'NKE' 'BKNG' 'CCL' 'BRK.B' 'MA' 'JNJ' 'AMT' 'LOW' 'KO'\n",
      " 'UPS' 'PG' 'ABNB']\n",
      "Sentiment distribution: sentiment\n",
      "1    5474\n",
      "0    4526\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples in the dataset:\", len(df))\n",
    "print(\"Sentiment distribution:\", df['sentiment'].value_counts())\n",
    "print(\"Companies in the dataset:\", df['ticker'].nunique())\n",
    "print(\"\\t+ in the dataset:\", df['ticker'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a249cbd",
   "metadata": {},
   "source": [
    "Loads daily price data for each stock ticker and stores them in a dictionary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c014aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies loaded in the dataset: 37\n"
     ]
    }
   ],
   "source": [
    "price_dir = Path(\"dataset/StockEmotions/price\")\n",
    "price_dfs = {}\n",
    "# for file in price_dir.glob(\"*.csv\"): #Lets only load the price data from previous companies\n",
    "for ticker in df['ticker'].unique():\n",
    "    file = price_dir / f\"{ticker.replace('.','-')}.csv\" #SPECIAL CASE:  BRK.B.csv -> BRK-B.csv\n",
    "    dfp = pd.read_csv(file, parse_dates=['Date'])\n",
    "    dfp['date'] = dfp['Date'].dt.date\n",
    "    dfp.set_index('date', inplace=True)\n",
    "    price_dfs[ticker] = dfp[['Open','Close','Adj Close', 'High', 'Low', 'Volume']] ## Lets load all the price data: it's free!\n",
    "\n",
    "print(\"Number of companies loaded in the dataset:\", len(price_dfs))\n",
    "assert(len(price_dfs) == len(df['ticker'].unique())) ## Double check, the previous for loop had generated one error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "352c6a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>92.099998</td>\n",
       "      <td>92.391998</td>\n",
       "      <td>92.391998</td>\n",
       "      <td>92.663002</td>\n",
       "      <td>91.611504</td>\n",
       "      <td>50130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>93.750000</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>93.207497</td>\n",
       "      <td>80580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>93.224998</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>94.309998</td>\n",
       "      <td>93.224998</td>\n",
       "      <td>75288000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.143997</td>\n",
       "      <td>95.143997</td>\n",
       "      <td>95.184502</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>81236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>95.224998</td>\n",
       "      <td>95.343002</td>\n",
       "      <td>95.343002</td>\n",
       "      <td>95.694504</td>\n",
       "      <td>94.601997</td>\n",
       "      <td>80898000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>159.695007</td>\n",
       "      <td>158.634506</td>\n",
       "      <td>158.634506</td>\n",
       "      <td>160.100006</td>\n",
       "      <td>158.449997</td>\n",
       "      <td>29038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>159.699997</td>\n",
       "      <td>164.197998</td>\n",
       "      <td>164.197998</td>\n",
       "      <td>165.199997</td>\n",
       "      <td>158.634506</td>\n",
       "      <td>113736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>165.496994</td>\n",
       "      <td>166.100006</td>\n",
       "      <td>166.100006</td>\n",
       "      <td>167.532501</td>\n",
       "      <td>164.061005</td>\n",
       "      <td>97458000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>167.050003</td>\n",
       "      <td>164.292496</td>\n",
       "      <td>164.292496</td>\n",
       "      <td>167.104996</td>\n",
       "      <td>164.123505</td>\n",
       "      <td>64186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>163.750000</td>\n",
       "      <td>162.846497</td>\n",
       "      <td>162.846497</td>\n",
       "      <td>164.145996</td>\n",
       "      <td>162.059998</td>\n",
       "      <td>59144000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open       Close   Adj Close        High         Low  \\\n",
       "date                                                                     \n",
       "2019-12-31   92.099998   92.391998   92.391998   92.663002   91.611504   \n",
       "2020-01-02   93.750000   94.900497   94.900497   94.900497   93.207497   \n",
       "2020-01-03   93.224998   93.748497   93.748497   94.309998   93.224998   \n",
       "2020-01-06   93.000000   95.143997   95.143997   95.184502   93.000000   \n",
       "2020-01-07   95.224998   95.343002   95.343002   95.694504   94.601997   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-12-24  159.695007  158.634506  158.634506  160.100006  158.449997   \n",
       "2020-12-28  159.699997  164.197998  164.197998  165.199997  158.634506   \n",
       "2020-12-29  165.496994  166.100006  166.100006  167.532501  164.061005   \n",
       "2020-12-30  167.050003  164.292496  164.292496  167.104996  164.123505   \n",
       "2020-12-31  163.750000  162.846497  162.846497  164.145996  162.059998   \n",
       "\n",
       "               Volume  \n",
       "date                   \n",
       "2019-12-31   50130000  \n",
       "2020-01-02   80580000  \n",
       "2020-01-03   75288000  \n",
       "2020-01-06   81236000  \n",
       "2020-01-07   80898000  \n",
       "...               ...  \n",
       "2020-12-24   29038000  \n",
       "2020-12-28  113736000  \n",
       "2020-12-29   97458000  \n",
       "2020-12-30   64186000  \n",
       "2020-12-31   59144000  \n",
       "\n",
       "[254 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_dfs[\"AMZN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12ed028",
   "metadata": {},
   "source": [
    "#### Filter by Available Price Data\n",
    "Removes tweets for tickers with no matching price history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In tweets but missing price data: set()\n"
     ]
    }
   ],
   "source": [
    "tickers = set(df['ticker'])\n",
    "available = set(price_dfs.keys())\n",
    "print(\"In tweets but missing price data:\", tickers - available)\n",
    "df = df[df['ticker'].isin(available)].reset_index(drop=True) ####¬†ALERT! the problem was that BRK.B was missing but the file was named BRK-B.csv!! NoW it's solved!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bebc15",
   "metadata": {},
   "source": [
    "### Load Pretrained Sentiment Model\n",
    "Loads the twitter-roberta-base-sentiment model and tokenizer to classify tweet sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "397d2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "labels = ['negative', 'neutral', 'positive']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681514a6",
   "metadata": {},
   "source": [
    "### Define Sentiment Prediction Function\n",
    "This function returns the predicted label and a sentiment score ‚àà [‚Äì1, 1] based on model probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "023a316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_finbert_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1)[0].numpy()\n",
    "    label = labels[probs.argmax()]\n",
    "    score = probs[2] - probs[0]  # positive - negative ‚Üí score ‚àà [-1, 1]\n",
    "    return label, float(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ca422",
   "metadata": {},
   "source": [
    "### Run Sentiment Inference on Tweets\n",
    "Applies the sentiment model to each tweet and stores the predicted label and score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675a2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [09:59, 16.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# df = df.dropna(subset=[\"text\"]).copy().reset_index(drop=True) > ? copy and drop?  \n",
    "textserie = df[\"text\"] ## Better to use the text column, and not remove all data\n",
    "\n",
    "labels_list = []\n",
    "scores_list = []\n",
    "\n",
    "for i,text in tqdm(enumerate(textserie)):\n",
    "    label, score = infer_finbert_sentiment(text)\n",
    "    labels_list.append(label)\n",
    "    scores_list.append(score)\n",
    "\n",
    "df['finbert_label'] = labels_list # We can do this, since we not alter the index/order\n",
    "df['finbert_score'] = scores_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea1d11",
   "metadata": {},
   "source": [
    "### Save Results\n",
    "Exports the enriched dataset with FinBERT sentiment to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "532d08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results/exp0/tweets_with_finbert_sentiment.csv\", index=False) \n",
    "# It's good to save the results in internal folder since these temporal files are not part of your core-project but from your experimentation. \n",
    "# And more easy to remove/clean!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2dd05",
   "metadata": {},
   "source": [
    "## Experiment - option 1 ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d78df",
   "metadata": {},
   "source": [
    "Charger la v√©rit√© terrain (senti_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd76a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date ticker                                               text  \\\n",
      "0  2020-01-01   AMZN       $AMZN Dow futures up by 100 points already ü•≥   \n",
      "1  2020-01-01   TSLA  $TSLA Daddy's drinkin' eArly tonight! Here's t...   \n",
      "2  2020-01-01   AAPL  $AAPL We‚Äôll been riding since last December fr...   \n",
      "3  2020-01-01   TSLA            $TSLA happy new year, 2020, everyoneüç∑üéâüôè   \n",
      "4  2020-01-01   TSLA  $TSLA haha just a collection of greats...\"Mars...   \n",
      "\n",
      "   sentiment finbert_label  finbert_score  \n",
      "0          1      positive       0.912322  \n",
      "1          1      positive       0.869287  \n",
      "2          1       neutral      -0.088177  \n",
      "3          1      positive       0.978799  \n",
      "4          1      positive       0.886038  \n",
      "         date ticker                                               text  \\\n",
      "0  2020-01-01   AMZN       $AMZN Dow futures up by 100 points already ü•≥   \n",
      "1  2020-01-01   TSLA  $TSLA Daddy's drinkin' eArly tonight! Here's t...   \n",
      "2  2020-01-01   AAPL  $AAPL We‚Äôll been riding since last December fr...   \n",
      "3  2020-01-01   TSLA            $TSLA happy new year, 2020, everyoneüç∑üéâüôè   \n",
      "4  2020-01-01   TSLA  $TSLA haha just a collection of greats...\"Mars...   \n",
      "\n",
      "  sentiment finbert_label  finbert_score  \n",
      "0  positive      positive       0.912322  \n",
      "1  positive      positive       0.869287  \n",
      "2  positive       neutral      -0.088177  \n",
      "3  positive      positive       0.978799  \n",
      "4  positive      positive       0.886038  \n"
     ]
    }
   ],
   "source": [
    "## BETTER We dont lose data. we can commment it\n",
    "## ALL is merged in the original DF\n",
    "\n",
    "\n",
    "# base = Path(\"StockEmotions/tweet\") \n",
    "# df_list = []\n",
    "\n",
    "# for split in [\"train_stockemo\", \"val_stockemo\", \"test_stockemo\"]:\n",
    "#     path = base / f\"{split}.csv\"\n",
    "#     df = pd.read_csv(path)\n",
    "#     df = df[['date','ticker','original','senti_label']]\n",
    "#     df.rename(columns={'original': 'text'}, inplace=True)\n",
    "#     df_list.append(df) \n",
    "\n",
    "# df_gold = pd.concat(df_list, ignore_index=True)\n",
    "# df_gold['date'] = pd.to_datetime(df_gold['date']).dt.date\n",
    "\n",
    "\n",
    "# df_pred = pd.read_csv(\"results/exp0/tweets_with_finbert_sentiment.csv\")\n",
    "# df_pred['date'] = pd.to_datetime(df_pred['date']).dt.date\n",
    "\n",
    "# # df = pd.merge(df_pred, df_gold, on=['date', 'ticker', 'text'], how='inner')\n",
    "\n",
    "# # V√©rifions que tout est bien align√©\n",
    "# df[['text', 'senti_label', 'finbert_label', 'finbert_score']].head()\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.read_csv(\"results/exp0/tweets_with_finbert_sentiment.csv\")\n",
    "# print(df.head())\n",
    "# df[\"sentiment\"] = df[\"sentiment\"].map({1: 'positive', 0: 'negative'})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6603b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4160\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive     0.7011    0.4850    0.5734      5474\n",
      "    negative     0.6356    0.3325    0.4366      4526\n",
      "\n",
      "   micro avg     0.6759    0.4160    0.5150     10000\n",
      "   macro avg     0.6683    0.4088    0.5050     10000\n",
      "weighted avg     0.6714    0.4160    0.5115     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Filtrer les cas o√π finbert_label est positive ou negative\n",
    "# df_strict = df[df['finbert_label'].isin(['positive', 'negative'])].copy()\n",
    "# map_labels = {'positive': 'bullish', 'negative': 'bearish'}\n",
    "# df_strict['finbert_mapped'] = df_strict['finbert_label'].map(map_labels)\n",
    "\n",
    "# √âvaluer\n",
    "###¬†ALERT: Dont create more df with the same data\n",
    "acc1 = accuracy_score(df['sentiment'], df['finbert_label']) \n",
    "print(f\"Accuracy: {acc1:.4f}\") \n",
    "# print(classification_report(df['sentiment'], df['finbert_label']))\n",
    "print(classification_report(df['sentiment'], df['finbert_label'], labels=['positive', 'negative'], zero_division=0,digits=4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddba26",
   "metadata": {},
   "source": [
    "###¬†Note on the results:\n",
    "- The prediction value is quite low (or bad) with this approximation, which is 0.5734 and 0.4366.\n",
    "- This is normal; don't worry! We'll try to improve it.\n",
    "- Now it's like flipping a coin (positive and negative - random binary). > 50%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6084c8ae",
   "metadata": {},
   "source": [
    "## Sentiment Model Evaluation ‚Äì Option 1 (Non-Neutral Predictions Only)\n",
    "\n",
    "We evaluated the FinBERT-based sentiment classification model on the subset of the dataset where predictions were either `positive` or `negative`, excluding `neutral` cases to focus on high-confidence sentiment detection.\n",
    "\n",
    "###  Evaluation Metrics\n",
    "\n",
    "| Sentiment | Precision | Recall | F1-Score | Support |\n",
    "|-----------|-----------|--------|----------|---------|\n",
    "| Bearish   | 0.63      | 0.57   | 0.60     | 2632    |\n",
    "| Bullish   | 0.70      | 0.75   | 0.73     | 3507    |\n",
    "| **Overall Accuracy** |       |        |          | **67.49%** |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40ba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>finbert_label</th>\n",
       "      <th>finbert_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>$AMZN Dow futures up by 100 points already ü•≥</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.912322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>$TSLA Daddy's drinkin' eArly tonight! Here's t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.869287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>$AAPL We‚Äôll been riding since last December fr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.088177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>$TSLA happy new year, 2020, everyoneüç∑üéâüôè</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.978799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>$TSLA haha just a collection of greats...\"Mars...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.886038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker                                               text  \\\n",
       "0  2020-01-01   AMZN       $AMZN Dow futures up by 100 points already ü•≥   \n",
       "1  2020-01-01   TSLA  $TSLA Daddy's drinkin' eArly tonight! Here's t...   \n",
       "2  2020-01-01   AAPL  $AAPL We‚Äôll been riding since last December fr...   \n",
       "3  2020-01-01   TSLA            $TSLA happy new year, 2020, everyoneüç∑üéâüôè   \n",
       "4  2020-01-01   TSLA  $TSLA haha just a collection of greats...\"Mars...   \n",
       "\n",
       "  sentiment finbert_label  finbert_score  \n",
       "0  positive      positive       0.912322  \n",
       "1  positive      positive       0.869287  \n",
       "2  positive       neutral      -0.088177  \n",
       "3  positive      positive       0.978799  \n",
       "4  positive      positive       0.886038  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Lets see the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8277a23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples with positive or negative values: 6155 from a total of 10000 , rate: 0.6155\n",
      "Option 2\n",
      "Accuracy (all): 0.6759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive     0.7011    0.7547    0.7269      3518\n",
      "    negative     0.6356    0.5707    0.6014      2637\n",
      "\n",
      "    accuracy                         0.6759      6155\n",
      "   macro avg     0.6683    0.6627    0.6641      6155\n",
      "weighted avg     0.6730    0.6759    0.6731      6155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df['finbert_binary'] = df['finbert_score'].apply(lambda x: 'bullish' if x > 0 else 'bearish')\n",
    "mask_binary =  df[df[\"finbert_label\"]!=\"neutral\"].index\n",
    "print(\"Samples with positive or negative values:\", len(mask_binary), \"from a total of\", len(df), \", rate:\", len(mask_binary)/len(df))\n",
    "# √âvaluer\n",
    "# df_all = df.dropna(subset=['senti_label', 'finbert_binary'])\n",
    "# acc2 = accuracy_score(df_all['senti_label'], df_all['finbert_binary'])\n",
    "# print(f\"Option 2 ‚Äì Accuracy (all): {acc2:.4f}\")\n",
    "# print(classification_report(df_all['senti_label'], df_all['finbert_binary']))\n",
    "\n",
    "print(\"Option 2\")\n",
    "acc2 = accuracy_score(df.loc[mask_binary,'sentiment'], df.loc[mask_binary]['finbert_label'])\n",
    "print(f\"Accuracy (all): {acc2:.4f}\")\n",
    "print(classification_report(df.loc[mask_binary,'sentiment'], df.loc[mask_binary]['finbert_label'], labels=['positive', 'negative'], zero_division=0,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b362f1d8",
   "metadata": {},
   "source": [
    "# NOTE on the results:\n",
    "- It's better, but we're losing the neutral value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1c69d",
   "metadata": {},
   "source": [
    "### Sorry, I dont understand the next code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf012fd",
   "metadata": {},
   "source": [
    "##  Sentiment Model Evaluation ‚Äì Option 2 (Full Dataset Using Score > 0)\n",
    "\n",
    "In this evaluation, we used the entire dataset by converting the continuous `finbert_score` into binary sentiment:\n",
    "\n",
    "- `bullish` if score > 0\n",
    "- `bearish` if score <= 0\n",
    "\n",
    "This includes all tweets, even those that may have had ambiguous or borderline sentiment.\n",
    "\n",
    "###  Evaluation Metrics\n",
    "\n",
    "| Sentiment | Precision | Recall | F1-Score | Support |\n",
    "|-----------|-----------|--------|----------|---------|\n",
    "| Bearish   | 0.61      | 0.54   | 0.58     | 4522    |\n",
    "| Bullish   | 0.65      | 0.71   | 0.68     | 5464    |\n",
    "| **Overall Accuracy** |       |        |          | **63.66%** |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d828a9",
   "metadata": {},
   "source": [
    "##  Conclusion\n",
    "\n",
    "The sentiment model based on FinBERT performs reasonably well, especially on clearly positive (bullish) tweets. It shows limitations on bearish detection but remains a solid foundation for further development.\n",
    "\n",
    "- **Final model score** (macro F1 average across both tests): **0.645**\n",
    "\n",
    "##  Next Step\n",
    "\n",
    "- Use sentiment scores to **generate trading signals**\n",
    "- Plan a **comparison with other models** ( FinGPT, LLMs with justification/explanation)\n",
    "- Prepare for **adding explainability (XAI)** to better interpret each sentiment prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b536ad",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
